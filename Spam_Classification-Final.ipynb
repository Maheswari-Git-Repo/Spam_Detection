{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('Text_HAM_SPAM_calssification.csv')\n",
    "\n",
    "#data=pd.read_csv('spam.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Your gonna have to pick up a $1 burger for you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Your gonna have to pick up a $1 burger for you..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Analyzing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5026, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5026 entries, 0 to 5025\n",
      "Data columns (total 2 columns):\n",
      "Category    1726 non-null object\n",
      "Message     1791 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 78.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category    3300\n",
       "Message     3235\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm at work. Please call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Then u drive lor.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Ard 515 like dat. Y?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Tell me they're female :V how're you throwing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>NaN</td>\n",
       "      <td>EASTENDERS TV Quiz. What FLOWER does DOT compa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5021</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5022</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5023</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5024</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5025</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3300 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category                                            Message\n",
       "1000      NaN                           I'm at work. Please call\n",
       "1001      NaN                                  Then u drive lor.\n",
       "1002      NaN                               Ard 515 like dat. Y?\n",
       "1003      NaN  Tell me they're female :V how're you throwing ...\n",
       "1004      NaN  EASTENDERS TV Quiz. What FLOWER does DOT compa...\n",
       "...       ...                                                ...\n",
       "5021      NaN                                                NaN\n",
       "5022      NaN                                                NaN\n",
       "5023      NaN                                                NaN\n",
       "5024      NaN                                                NaN\n",
       "5025      NaN                                                NaN\n",
       "\n",
       "[3300 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['Category'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3235"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[data['Message'].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(data[data.columns[data.isna().any()]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.drop(data[data[\"Category\"]==\"NaN\"].index,axis = 0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping rows with null values\n",
    "\n",
    "data_clean=data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1726, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category    0\n",
       "Message     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Your gonna have to pick up a $1 burger for you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Your gonna have to pick up a $1 burger for you..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#data_clean['Length']=data_clean['Message'].apply(len)\n",
    "\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     1490\n",
       "spam     236\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.Category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage for default\n",
      "\n",
      "ham     86.33\n",
      "spam    13.67\n",
      "Name: Category, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "print('Percentage for default\\n')\n",
    "print(round(data_clean.Category.value_counts(normalize=True)*100,2))\n",
    "round(data_clean.Category.value_counts(normalize=True)*100,2).plot(kind='bar')\n",
    "plt.title('Percentage Distributions by review category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <td>1726</td>\n",
       "      <td>2</td>\n",
       "      <td>ham</td>\n",
       "      <td>1490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Message</th>\n",
       "      <td>1726</td>\n",
       "      <td>1667</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count unique                     top  freq\n",
       "Category  1726      2                     ham  1490\n",
       "Message   1726   1667  Sorry, I'll call later    10"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Your gonna have to pick up a $1 burger for you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Your gonna have to pick up a $1 burger for you..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1726 entries, 0 to 1790\n",
      "Data columns (total 2 columns):\n",
      "Category    1726 non-null object\n",
      "Message     1726 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 40.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "print (string.punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing Stop words and punctuations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_Data(text):\n",
    "    text = re.sub(r\"didn't\", \"did not\", text)\n",
    "    text = re.sub(r\"don't\", \"do not\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"can not\", text)\n",
    "    text = re.sub(r\"wasn't\", \"do not\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'s\", \" is\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "    \n",
    "    text=str(text).lower()\n",
    "    \n",
    "    p=set(string.punctuation)\n",
    "    for i in range(10):\n",
    "        p.add(str(i))\n",
    "        \n",
    "    words=text.split()\n",
    "    text=[]\n",
    "    for word in words:\n",
    "        text_word=''.join(i for i in word if i not in p)\n",
    "        text.append(text_word)\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop=set(stopwords.words('english'))\n",
    "#stop.remove('no')\n",
    "#stop.remove('not')\n",
    "#print (stop)\n",
    "\n",
    "\n",
    "clean_doc=[]\n",
    "for doc in data_clean['Message'].values:\n",
    "    clean_text=clean_Data(doc)\n",
    "    if len(clean_text)!=0:\n",
    "        clean_doc.append(clean_text)\n",
    "    else:\n",
    "        clean_doc.append('NAN')\n",
    "    \n",
    "data_clean['Cleaned_data']=clean_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1726, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category        1\n",
       "Message         1\n",
       "Cleaned_data    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean[data_clean['Cleaned_data']=='NAN'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>Cleaned_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1556</th>\n",
       "      <td>ham</td>\n",
       "      <td>645</td>\n",
       "      <td>NAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category Message Cleaned_data\n",
       "1556      ham     645          NAN"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean[data_clean['Cleaned_data']=='NAN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RajMahendra\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "data_clean.drop(data_clean[data_clean[\"Cleaned_data\"]=='NAN'].index,axis = 0,inplace = True) # deleting rows that have no text \n",
    "data_clean=data_clean.reset_index(drop='true') # after deleting rows index should be reset\n",
    "data_clean['Category']= data_clean['Category'].replace('ham',0)\n",
    "data_clean['Category']= data_clean['Category'].replace('spam',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>Cleaned_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry in  a wkly comp to win fa cup final...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>As a valued customer, I am pleased to advise y...</td>\n",
       "      <td>as a valued customer i am pleased to advise yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>Urgent UR awarded a complimentary trip to Euro...</td>\n",
       "      <td>urgent ur awarded a complimentary trip to euro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>Did you hear about the new \"Divorce Barbie\"? I...</td>\n",
       "      <td>did you hear about the new divorce barbie it c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "      <td>please call our customer service representativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>1</td>\n",
       "      <td>BIG BROTHER ALERT! The computer has selected u...</td>\n",
       "      <td>big brother alert the computer has selected u ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>1</td>\n",
       "      <td>WIN: We have a winner! Mr. T. Foley won an iPo...</td>\n",
       "      <td>win we have a winner mr t foley won an ipod mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>1</td>\n",
       "      <td>Todays Voda numbers ending 1225 are selected t...</td>\n",
       "      <td>todays voda numbers ending  are selected to re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1708</th>\n",
       "      <td>1</td>\n",
       "      <td>Hottest pics straight to your phone!! See me g...</td>\n",
       "      <td>hottest pics straight to your phone see me get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1717</th>\n",
       "      <td>1</td>\n",
       "      <td>Hack Chat. Get backdoor entry into 121 chat ro...</td>\n",
       "      <td>hack chat get backdoor entry into  chat rooms ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>236 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Category                                            Message  \\\n",
       "2            1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "9            1  As a valued customer, I am pleased to advise y...   \n",
       "11           1  Urgent UR awarded a complimentary trip to Euro...   \n",
       "12           1  Did you hear about the new \"Divorce Barbie\"? I...   \n",
       "37           1  Please call our customer service representativ...   \n",
       "...        ...                                                ...   \n",
       "1659         1  BIG BROTHER ALERT! The computer has selected u...   \n",
       "1671         1  WIN: We have a winner! Mr. T. Foley won an iPo...   \n",
       "1685         1  Todays Voda numbers ending 1225 are selected t...   \n",
       "1708         1  Hottest pics straight to your phone!! See me g...   \n",
       "1717         1  Hack Chat. Get backdoor entry into 121 chat ro...   \n",
       "\n",
       "                                           Cleaned_data  \n",
       "2     free entry in  a wkly comp to win fa cup final...  \n",
       "9     as a valued customer i am pleased to advise yo...  \n",
       "11    urgent ur awarded a complimentary trip to euro...  \n",
       "12    did you hear about the new divorce barbie it c...  \n",
       "37    please call our customer service representativ...  \n",
       "...                                                 ...  \n",
       "1659  big brother alert the computer has selected u ...  \n",
       "1671  win we have a winner mr t foley won an ipod mo...  \n",
       "1685  todays voda numbers ending  are selected to re...  \n",
       "1708  hottest pics straight to your phone see me get...  \n",
       "1717  hack chat get backdoor entry into  chat rooms ...  \n",
       "\n",
       "[236 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean[data_clean['Category']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category        0\n",
       "Message         0\n",
       "Cleaned_data    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean[data_clean['Cleaned_data']=='NAN'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1725, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stemming**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "s=SnowballStemmer(\"english\")\n",
    "\n",
    "clean_doc1=[]\n",
    "for sent in data_clean['Cleaned_data'].values:\n",
    "    d=' '.join(s.stem(word) for word in sent.split())\n",
    "    clean_doc1.append(d)\n",
    "\n",
    "data_clean['Cleaned_data1']=clean_doc1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>Cleaned_data</th>\n",
       "      <th>Cleaned_data1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>go until jurong point crazi avail onli in bugi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>ok lar joke wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry in  a wkly comp to win fa cup final...</td>\n",
       "      <td>free entri in a wkli comp to win fa cup final ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "      <td>u dun say so earli hor u c alreadi then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Your gonna have to pick up a $1 burger for you...</td>\n",
       "      <td>your gonna have to pick up a  burger for yours...</td>\n",
       "      <td>your gonna have to pick up a burger for yourse...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category                                            Message  \\\n",
       "0         0  Go until jurong point, crazy.. Available only ...   \n",
       "1         0                      Ok lar... Joking wif u oni...   \n",
       "2         1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3         0  U dun say so early hor... U c already then say...   \n",
       "4         0  Your gonna have to pick up a $1 burger for you...   \n",
       "\n",
       "                                        Cleaned_data  \\\n",
       "0  go until jurong point crazy available only in ...   \n",
       "1                            ok lar joking wif u oni   \n",
       "2  free entry in  a wkly comp to win fa cup final...   \n",
       "3        u dun say so early hor u c already then say   \n",
       "4  your gonna have to pick up a  burger for yours...   \n",
       "\n",
       "                                       Cleaned_data1  \n",
       "0  go until jurong point crazi avail onli in bugi...  \n",
       "1                              ok lar joke wif u oni  \n",
       "2  free entri in a wkli comp to win fa cup final ...  \n",
       "3        u dun say so earli hor u c alreadi then say  \n",
       "4  your gonna have to pick up a burger for yourse...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.Category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean.rename({'Cleaned_data1':'Cleaned_data_new'},axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>Cleaned_data</th>\n",
       "      <th>Cleaned_data_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>go until jurong point crazi avail onli in bugi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>ok lar joke wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry in  a wkly comp to win fa cup final...</td>\n",
       "      <td>free entri in a wkli comp to win fa cup final ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "      <td>u dun say so earli hor u c alreadi then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Your gonna have to pick up a $1 burger for you...</td>\n",
       "      <td>your gonna have to pick up a  burger for yours...</td>\n",
       "      <td>your gonna have to pick up a burger for yourse...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category                                            Message  \\\n",
       "0         0  Go until jurong point, crazy.. Available only ...   \n",
       "1         0                      Ok lar... Joking wif u oni...   \n",
       "2         1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3         0  U dun say so early hor... U c already then say...   \n",
       "4         0  Your gonna have to pick up a $1 burger for you...   \n",
       "\n",
       "                                        Cleaned_data  \\\n",
       "0  go until jurong point crazy available only in ...   \n",
       "1                            ok lar joking wif u oni   \n",
       "2  free entry in  a wkly comp to win fa cup final...   \n",
       "3        u dun say so early hor u c already then say   \n",
       "4  your gonna have to pick up a  burger for yours...   \n",
       "\n",
       "                                    Cleaned_data_new  \n",
       "0  go until jurong point crazi avail onli in bugi...  \n",
       "1                              ok lar joke wif u oni  \n",
       "2  free entri in a wkli comp to win fa cup final ...  \n",
       "3        u dun say so earli hor u c alreadi then say  \n",
       "4  your gonna have to pick up a burger for yourse...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Length=data_clean['Message'].apply(len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>Cleaned_data</th>\n",
       "      <th>Cleaned_data_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>go until jurong point crazi avail onli in bugi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>ok lar joke wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry in  a wkly comp to win fa cup final...</td>\n",
       "      <td>free entri in a wkli comp to win fa cup final ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "      <td>u dun say so earli hor u c alreadi then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Your gonna have to pick up a $1 burger for you...</td>\n",
       "      <td>your gonna have to pick up a  burger for yours...</td>\n",
       "      <td>your gonna have to pick up a burger for yourse...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category                                            Message  \\\n",
       "0         0  Go until jurong point, crazy.. Available only ...   \n",
       "1         0                      Ok lar... Joking wif u oni...   \n",
       "2         1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3         0  U dun say so early hor... U c already then say...   \n",
       "4         0  Your gonna have to pick up a $1 burger for you...   \n",
       "\n",
       "                                        Cleaned_data  \\\n",
       "0  go until jurong point crazy available only in ...   \n",
       "1                            ok lar joking wif u oni   \n",
       "2  free entry in  a wkly comp to win fa cup final...   \n",
       "3        u dun say so early hor u c already then say   \n",
       "4  your gonna have to pick up a  burger for yours...   \n",
       "\n",
       "                                    Cleaned_data_new  \n",
       "0  go until jurong point crazi avail onli in bugi...  \n",
       "1                              ok lar joke wif u oni  \n",
       "2  free entri in a wkli comp to win fa cup final ...  \n",
       "3        u dun say so earli hor u c alreadi then say  \n",
       "4  your gonna have to pick up a burger for yourse...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data_clean['Cleaned_data_new']\n",
    "y=data_clean['Category']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    go until jurong point crazi avail onli in bugi...\n",
       "1                                ok lar joke wif u oni\n",
       "2    free entri in a wkli comp to win fa cup final ...\n",
       "3          u dun say so earli hor u c alreadi then say\n",
       "4    your gonna have to pick up a burger for yourse...\n",
       "Name: Cleaned_data_new, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Bag of Words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1725, 3779)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "tvec = CountVectorizer()\n",
    "\n",
    "#converting sentences to Tf-Idf vectors\n",
    "X=tvec.fit_transform(df)\n",
    "\n",
    "print (X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aah',\n",
       " 'aaniy',\n",
       " 'aaooooright',\n",
       " 'aathilov',\n",
       " 'aathiwher',\n",
       " 'aberdeen',\n",
       " 'abil',\n",
       " 'abiola',\n",
       " 'abl',\n",
       " 'abnorm',\n",
       " 'about',\n",
       " 'abt',\n",
       " 'aburo',\n",
       " 'ac',\n",
       " 'acc',\n",
       " 'accentur',\n",
       " 'accept',\n",
       " 'access',\n",
       " 'accid',\n",
       " 'accident',\n",
       " 'accommod',\n",
       " 'accomod',\n",
       " 'accordinglyor',\n",
       " 'account',\n",
       " 'ach',\n",
       " 'acid',\n",
       " 'acknowledg',\n",
       " 'acoentri',\n",
       " 'across',\n",
       " 'acsmsreward',\n",
       " 'act',\n",
       " 'action',\n",
       " 'activ',\n",
       " 'actor',\n",
       " 'actual',\n",
       " 'acwicmbcktzr',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'add',\n",
       " 'addamsfa',\n",
       " 'addi',\n",
       " 'addict',\n",
       " 'address',\n",
       " 'addressu',\n",
       " 'administr',\n",
       " 'admir',\n",
       " 'admiti',\n",
       " 'ador',\n",
       " 'adult',\n",
       " 'advanc',\n",
       " 'adventur',\n",
       " 'advis',\n",
       " 'ae',\n",
       " 'aeronaut',\n",
       " 'aeroplan',\n",
       " 'affect',\n",
       " 'afghanistan',\n",
       " 'afraid',\n",
       " 'aft',\n",
       " 'after',\n",
       " 'afternoon',\n",
       " 'aftr',\n",
       " 'ag',\n",
       " 'again',\n",
       " 'againcal',\n",
       " 'against',\n",
       " 'age',\n",
       " 'agent',\n",
       " 'agesr',\n",
       " 'ago',\n",
       " 'agre',\n",
       " 'ah',\n",
       " 'aha',\n",
       " 'ahead',\n",
       " 'ahge',\n",
       " 'ahnow',\n",
       " 'ahold',\n",
       " 'ahsen',\n",
       " 'ahth',\n",
       " 'ahwhat',\n",
       " 'aid',\n",
       " 'aig',\n",
       " 'aight',\n",
       " 'ain',\n",
       " 'aint',\n",
       " 'air',\n",
       " 'airport',\n",
       " 'aiya',\n",
       " 'aiyah',\n",
       " 'aiyar',\n",
       " 'aiyo',\n",
       " 'aj',\n",
       " 'ak',\n",
       " 'al',\n",
       " 'alaipayuth',\n",
       " 'album',\n",
       " 'alcohol',\n",
       " 'alert',\n",
       " 'alertfrom',\n",
       " 'alex',\n",
       " 'alfi',\n",
       " 'algarv',\n",
       " 'algorithm',\n",
       " 'ali',\n",
       " 'alibi',\n",
       " 'aliv',\n",
       " 'alivebett',\n",
       " 'all',\n",
       " 'allahmeet',\n",
       " 'allahrakhesh',\n",
       " 'allo',\n",
       " 'allow',\n",
       " 'almost',\n",
       " 'alon',\n",
       " 'along',\n",
       " 'alreadi',\n",
       " 'alright',\n",
       " 'alrightokay',\n",
       " 'alrit',\n",
       " 'also',\n",
       " 'alter',\n",
       " 'alternativehop',\n",
       " 'although',\n",
       " 'alway',\n",
       " 'alwi',\n",
       " 'am',\n",
       " 'ama',\n",
       " 'american',\n",
       " 'ami',\n",
       " 'ammo',\n",
       " 'among',\n",
       " 'amor',\n",
       " 'amp',\n",
       " 'ampm',\n",
       " 'amt',\n",
       " 'an',\n",
       " 'ana',\n",
       " 'analysi',\n",
       " 'and',\n",
       " 'andrewsboy',\n",
       " 'anetwork',\n",
       " 'angri',\n",
       " 'ani',\n",
       " 'anim',\n",
       " 'anji',\n",
       " 'anniversari',\n",
       " 'annonc',\n",
       " 'announc',\n",
       " 'annoy',\n",
       " 'anot',\n",
       " 'anoth',\n",
       " 'ansr',\n",
       " 'answer',\n",
       " 'anthoni',\n",
       " 'anti',\n",
       " 'anybodi',\n",
       " 'anyhow',\n",
       " 'anymor',\n",
       " 'anyon',\n",
       " 'anyth',\n",
       " 'anythin',\n",
       " 'anytim',\n",
       " 'anyway',\n",
       " 'anywher',\n",
       " 'apart',\n",
       " 'apeshit',\n",
       " 'apologis',\n",
       " 'app',\n",
       " 'appar',\n",
       " 'applebe',\n",
       " 'applespairsal',\n",
       " 'appli',\n",
       " 'applic',\n",
       " 'appoint',\n",
       " 'appreci',\n",
       " 'approach',\n",
       " 'appropri',\n",
       " 'approx',\n",
       " 'appt',\n",
       " 'apr',\n",
       " 'april',\n",
       " 'apt',\n",
       " 'aptitud',\n",
       " 'ar',\n",
       " 'arcad',\n",
       " 'ard',\n",
       " 'are',\n",
       " 'area',\n",
       " 'aren',\n",
       " 'argu',\n",
       " 'argument',\n",
       " 'ari',\n",
       " 'arm',\n",
       " 'arng',\n",
       " 'arngd',\n",
       " 'around',\n",
       " 'arrang',\n",
       " 'arriv',\n",
       " 'arsenal',\n",
       " 'artist',\n",
       " 'arun',\n",
       " 'as',\n",
       " 'asap',\n",
       " 'ashley',\n",
       " 'ask',\n",
       " 'askd',\n",
       " 'askin',\n",
       " 'asleep',\n",
       " 'ass',\n",
       " 'assum',\n",
       " 'astn',\n",
       " 'astound',\n",
       " 'at',\n",
       " 'ate',\n",
       " 'athlet',\n",
       " 'atlanta',\n",
       " 'atleast',\n",
       " 'atm',\n",
       " 'attach',\n",
       " 'attempt',\n",
       " 'atten',\n",
       " 'attend',\n",
       " 'attitud',\n",
       " 'attract',\n",
       " 'attractioni',\n",
       " 'attribut',\n",
       " 'auction',\n",
       " 'audrey',\n",
       " 'august',\n",
       " 'aunt',\n",
       " 'aunti',\n",
       " 'aust',\n",
       " 'ava',\n",
       " 'avail',\n",
       " 'availa',\n",
       " 'availablei',\n",
       " 'avalarr',\n",
       " 'ave',\n",
       " 'avent',\n",
       " 'avoid',\n",
       " 'await',\n",
       " 'awak',\n",
       " 'award',\n",
       " 'away',\n",
       " 'awesom',\n",
       " 'ax',\n",
       " 'axi',\n",
       " 'ayn',\n",
       " 'ba',\n",
       " 'baaaaab',\n",
       " 'babe',\n",
       " 'babi',\n",
       " 'babyhop',\n",
       " 'babyjontet',\n",
       " 'bac',\n",
       " 'back',\n",
       " 'backa',\n",
       " 'backdoor',\n",
       " 'bad',\n",
       " 'bag',\n",
       " 'bagi',\n",
       " 'bahama',\n",
       " 'baig',\n",
       " 'bak',\n",
       " 'bakra',\n",
       " 'bakrid',\n",
       " 'balanc',\n",
       " 'balloon',\n",
       " 'bam',\n",
       " 'bangb',\n",
       " 'bangbab',\n",
       " 'bani',\n",
       " 'bank',\n",
       " 'banter',\n",
       " 'bao',\n",
       " 'bar',\n",
       " 'barbi',\n",
       " 'bare',\n",
       " 'bash',\n",
       " 'basic',\n",
       " 'basqihav',\n",
       " 'bat',\n",
       " 'batch',\n",
       " 'bath',\n",
       " 'bathroom',\n",
       " 'batteri',\n",
       " 'bay',\n",
       " 'bb',\n",
       " 'bbc',\n",
       " 'bcm',\n",
       " 'bcmwcnxx',\n",
       " 'bcoz',\n",
       " 'bcum',\n",
       " 'bday',\n",
       " 'be',\n",
       " 'beauti',\n",
       " 'beautifulmay',\n",
       " 'bec',\n",
       " 'becaus',\n",
       " 'becom',\n",
       " 'becoz',\n",
       " 'bed',\n",
       " 'bedbut',\n",
       " 'bedroom',\n",
       " 'bedroomlov',\n",
       " 'been',\n",
       " 'beer',\n",
       " 'beerag',\n",
       " 'befor',\n",
       " 'beforehand',\n",
       " 'beforew',\n",
       " 'beg',\n",
       " 'begin',\n",
       " 'behav',\n",
       " 'bein',\n",
       " 'believ',\n",
       " 'bellearli',\n",
       " 'belli',\n",
       " 'belliger',\n",
       " 'belov',\n",
       " 'belovd',\n",
       " 'beneath',\n",
       " 'beneficiari',\n",
       " 'best',\n",
       " 'bestcongrat',\n",
       " 'bestrpli',\n",
       " 'bet',\n",
       " 'beta',\n",
       " 'beth',\n",
       " 'betta',\n",
       " 'better',\n",
       " 'bettersn',\n",
       " 'between',\n",
       " 'bewar',\n",
       " 'bf',\n",
       " 'bfore',\n",
       " 'bian',\n",
       " 'biatch',\n",
       " 'bid',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'bike',\n",
       " 'bill',\n",
       " 'bilo',\n",
       " 'bin',\n",
       " 'biola',\n",
       " 'bird',\n",
       " 'birla',\n",
       " 'birthdat',\n",
       " 'birthday',\n",
       " 'bishan',\n",
       " 'bit',\n",
       " 'bite',\n",
       " 'biz',\n",
       " 'bk',\n",
       " 'black',\n",
       " 'blah',\n",
       " 'blake',\n",
       " 'blame',\n",
       " 'blank',\n",
       " 'blanket',\n",
       " 'blastin',\n",
       " 'bleak',\n",
       " 'bleh',\n",
       " 'bless',\n",
       " 'blessget',\n",
       " 'blimey',\n",
       " 'blind',\n",
       " 'blog',\n",
       " 'bloke',\n",
       " 'blood',\n",
       " 'bloodi',\n",
       " 'blown',\n",
       " 'blue',\n",
       " 'bluetooth',\n",
       " 'bluetoothhdset',\n",
       " 'bmw',\n",
       " 'bodi',\n",
       " 'boggi',\n",
       " 'bold',\n",
       " 'boltblu',\n",
       " 'bonus',\n",
       " 'boo',\n",
       " 'book',\n",
       " 'bookmark',\n",
       " 'bookshelf',\n",
       " 'boooo',\n",
       " 'bootydeli',\n",
       " 'bore',\n",
       " 'borin',\n",
       " 'borrow',\n",
       " 'boss',\n",
       " 'boston',\n",
       " 'both',\n",
       " 'bother',\n",
       " 'bought',\n",
       " 'bout',\n",
       " 'bowl',\n",
       " 'box',\n",
       " 'boxqu',\n",
       " 'boxskch',\n",
       " 'boxwrc',\n",
       " 'boy',\n",
       " 'boyf',\n",
       " 'boyfriend',\n",
       " 'boytoy',\n",
       " 'brain',\n",
       " 'brand',\n",
       " 'brave',\n",
       " 'break',\n",
       " 'breath',\n",
       " 'breez',\n",
       " 'bribe',\n",
       " 'bridg',\n",
       " 'bridgwat',\n",
       " 'bright',\n",
       " 'brighten',\n",
       " 'bring',\n",
       " 'bristol',\n",
       " 'british',\n",
       " 'britney',\n",
       " 'broken',\n",
       " 'brotha',\n",
       " 'brother',\n",
       " 'brought',\n",
       " 'browni',\n",
       " 'brows',\n",
       " 'browsin',\n",
       " 'bruv',\n",
       " 'bslvyl',\n",
       " 'bstfrnd',\n",
       " 'bt',\n",
       " 'btw',\n",
       " 'buck',\n",
       " 'bud',\n",
       " 'buen',\n",
       " 'buff',\n",
       " 'buffet',\n",
       " 'bugi',\n",
       " 'build',\n",
       " 'bun',\n",
       " 'bunker',\n",
       " 'burger',\n",
       " 'burial',\n",
       " 'burn',\n",
       " 'bus',\n",
       " 'buse',\n",
       " 'busetop',\n",
       " 'busi',\n",
       " 'busti',\n",
       " 'but',\n",
       " 'butt',\n",
       " 'button',\n",
       " 'buy',\n",
       " 'buzi',\n",
       " 'buzz',\n",
       " 'bx',\n",
       " 'bxipw',\n",
       " 'by',\n",
       " 'bye',\n",
       " 'cabin',\n",
       " 'cafe',\n",
       " 'cage',\n",
       " 'cake',\n",
       " 'cal',\n",
       " 'calcul',\n",
       " 'cali',\n",
       " 'call',\n",
       " 'callcost',\n",
       " 'calld',\n",
       " 'calldrov',\n",
       " 'caller',\n",
       " 'callertun',\n",
       " 'callfreefon',\n",
       " 'callin',\n",
       " 'callingforgot',\n",
       " 'calloptoutfq',\n",
       " 'calloptoutndx',\n",
       " 'calls',\n",
       " 'callsmessagesmiss',\n",
       " 'calm',\n",
       " 'cam',\n",
       " 'camcord',\n",
       " 'came',\n",
       " 'camera',\n",
       " 'campus',\n",
       " 'can',\n",
       " 'canada',\n",
       " 'cancel',\n",
       " 'canlov',\n",
       " 'cannot',\n",
       " 'cant',\n",
       " 'cappuccino',\n",
       " 'car',\n",
       " 'card',\n",
       " 'cardiff',\n",
       " 'cardin',\n",
       " 'care',\n",
       " 'careabout',\n",
       " 'career',\n",
       " 'carent',\n",
       " 'carlo',\n",
       " 'carolin',\n",
       " 'carpark',\n",
       " 'carryin',\n",
       " 'cartoon',\n",
       " 'case',\n",
       " 'cash',\n",
       " 'cashbal',\n",
       " 'cashin',\n",
       " 'cashto',\n",
       " 'castor',\n",
       " 'casualti',\n",
       " 'catch',\n",
       " 'caught',\n",
       " 'caus',\n",
       " 'caveboy',\n",
       " 'cbe',\n",
       " 'cc',\n",
       " 'ccna',\n",
       " 'cd',\n",
       " 'cds',\n",
       " 'celeb',\n",
       " 'celebr',\n",
       " 'cell',\n",
       " 'center',\n",
       " 'centr',\n",
       " 'cer',\n",
       " 'certain',\n",
       " 'certif',\n",
       " 'cha',\n",
       " 'chad',\n",
       " 'champ',\n",
       " 'champney',\n",
       " 'chanc',\n",
       " 'chang',\n",
       " 'channel',\n",
       " 'chap',\n",
       " 'charact',\n",
       " 'charg',\n",
       " 'chariti',\n",
       " 'charl',\n",
       " 'charli',\n",
       " 'chart',\n",
       " 'chase',\n",
       " 'chat',\n",
       " 'chatter',\n",
       " 'cheap',\n",
       " 'cheaper',\n",
       " 'chechi',\n",
       " 'check',\n",
       " 'cheek',\n",
       " 'cheeri',\n",
       " 'chef',\n",
       " 'chennai',\n",
       " 'chequ',\n",
       " 'cherthalain',\n",
       " 'cheyyamoand',\n",
       " 'chez',\n",
       " 'chicken',\n",
       " 'chikku',\n",
       " 'chikkuali',\n",
       " 'chikkudb',\n",
       " 'chikkugo',\n",
       " 'chikkuil',\n",
       " 'chikkusimpl',\n",
       " 'childish',\n",
       " 'children',\n",
       " 'chill',\n",
       " 'chillin',\n",
       " 'chinchilla',\n",
       " 'chines',\n",
       " 'chinki',\n",
       " 'chip',\n",
       " 'chk',\n",
       " 'chocol',\n",
       " 'choic',\n",
       " 'choos',\n",
       " 'chord',\n",
       " 'chore',\n",
       " 'chosen',\n",
       " 'christian',\n",
       " 'christma',\n",
       " 'christmasmerri',\n",
       " 'chuckin',\n",
       " 'church',\n",
       " 'cine',\n",
       " 'cinema',\n",
       " 'citi',\n",
       " 'claim',\n",
       " 'claimcod',\n",
       " 'clair',\n",
       " 'class',\n",
       " 'classmat',\n",
       " 'clean',\n",
       " 'clear',\n",
       " 'click',\n",
       " 'cliff',\n",
       " 'clock',\n",
       " 'clos',\n",
       " 'close',\n",
       " 'closer',\n",
       " 'closingd',\n",
       " 'cloth',\n",
       " 'cloud',\n",
       " 'club',\n",
       " 'clubmobilescom',\n",
       " 'clue',\n",
       " 'cm',\n",
       " 'co',\n",
       " 'coat',\n",
       " 'coax',\n",
       " 'cochin',\n",
       " 'cock',\n",
       " 'code',\n",
       " 'coffe',\n",
       " 'coin',\n",
       " 'cold',\n",
       " 'collect',\n",
       " 'colleg',\n",
       " 'colour',\n",
       " 'combin',\n",
       " 'come',\n",
       " 'comedyc',\n",
       " 'comin',\n",
       " 'comingdown',\n",
       " 'comingtmorow',\n",
       " 'comment',\n",
       " 'commerci',\n",
       " 'communiti',\n",
       " 'comp',\n",
       " 'compani',\n",
       " 'companion',\n",
       " 'compass',\n",
       " 'competit',\n",
       " 'complain',\n",
       " 'complet',\n",
       " 'complex',\n",
       " 'complimentari',\n",
       " 'comprehens',\n",
       " 'compromis',\n",
       " 'compulsori',\n",
       " 'comput',\n",
       " 'computerless',\n",
       " 'comuk',\n",
       " 'conact',\n",
       " 'concentr',\n",
       " 'concern',\n",
       " 'condit',\n",
       " 'conduct',\n",
       " 'conect',\n",
       " 'confer',\n",
       " 'confid',\n",
       " 'confirm',\n",
       " 'confus',\n",
       " 'congrat',\n",
       " 'congratul',\n",
       " 'connect',\n",
       " 'consid',\n",
       " 'consist',\n",
       " 'consol',\n",
       " 'constant',\n",
       " 'contact',\n",
       " 'content',\n",
       " 'contract',\n",
       " 'control',\n",
       " 'conveni',\n",
       " 'convert',\n",
       " 'convey',\n",
       " 'convinc',\n",
       " 'convincingjust',\n",
       " 'cooki',\n",
       " 'cool',\n",
       " 'coop',\n",
       " 'cope',\n",
       " 'copi',\n",
       " 'corect',\n",
       " 'corpor',\n",
       " 'correct',\n",
       " 'correctionor',\n",
       " 'corvett',\n",
       " 'cos',\n",
       " 'cost',\n",
       " 'costum',\n",
       " 'cougarpen',\n",
       " 'could',\n",
       " 'couldn',\n",
       " 'countin',\n",
       " 'countri',\n",
       " 'coupl',\n",
       " 'courag',\n",
       " 'cours',\n",
       " 'coveragd',\n",
       " 'coz',\n",
       " 'cozsomtim',\n",
       " 'cr',\n",
       " 'cramp',\n",
       " 'crap',\n",
       " 'crash',\n",
       " 'crave',\n",
       " 'crazi',\n",
       " 'craziest',\n",
       " 'crbt',\n",
       " 'cream',\n",
       " 'creat',\n",
       " 'credit',\n",
       " 'creepi',\n",
       " 'cresubi',\n",
       " 'cri',\n",
       " 'cricket',\n",
       " 'cro',\n",
       " 'cross',\n",
       " 'croydon',\n",
       " 'crucial',\n",
       " 'cruis',\n",
       " 'cruisin',\n",
       " 'crush',\n",
       " 'cs',\n",
       " 'cstore',\n",
       " 'ctagg',\n",
       " 'ctargg',\n",
       " 'ctla',\n",
       " 'cttargg',\n",
       " 'ctter',\n",
       " 'cttergg',\n",
       " 'cuck',\n",
       " 'cud',\n",
       " 'cuddl',\n",
       " 'cudnt',\n",
       " 'cultur',\n",
       " 'cum',\n",
       " 'cumin',\n",
       " 'cup',\n",
       " 'curfew',\n",
       " 'current',\n",
       " 'curri',\n",
       " 'cust',\n",
       " 'custcar',\n",
       " 'custom',\n",
       " 'cut',\n",
       " 'cute',\n",
       " 'cutefrnd',\n",
       " 'cutter',\n",
       " 'cuz',\n",
       " 'cwwx',\n",
       " 'cya',\n",
       " 'da',\n",
       " 'dad',\n",
       " 'daddi',\n",
       " 'dagood',\n",
       " 'dahow',\n",
       " 'dai',\n",
       " 'daili',\n",
       " 'dammit',\n",
       " 'damn',\n",
       " 'danc',\n",
       " 'dancc',\n",
       " 'dang',\n",
       " 'danger',\n",
       " 'dao',\n",
       " 'darker',\n",
       " 'darl',\n",
       " 'darlin',\n",
       " 'darren',\n",
       " 'dartboard',\n",
       " 'dat',\n",
       " 'data',\n",
       " 'date',\n",
       " 'dateboxessexcmxn',\n",
       " 'datz',\n",
       " 'dave',\n",
       " 'dawhat',\n",
       " 'dawn',\n",
       " 'day',\n",
       " 'daysh',\n",
       " 'daysÃ¨n',\n",
       " 'daytim',\n",
       " 'dayu',\n",
       " 'db',\n",
       " 'de',\n",
       " 'dead',\n",
       " 'deal',\n",
       " 'dealer',\n",
       " 'dealfarm',\n",
       " 'dear',\n",
       " 'dearer',\n",
       " 'deari',\n",
       " 'dearm',\n",
       " 'dearrakhesh',\n",
       " 'dearregret',\n",
       " 'dearshal',\n",
       " 'dec',\n",
       " 'decemb',\n",
       " 'decid',\n",
       " 'decis',\n",
       " 'deck',\n",
       " 'dedic',\n",
       " 'deep',\n",
       " 'deepak',\n",
       " 'deeraj',\n",
       " 'def',\n",
       " 'definit',\n",
       " 'defo',\n",
       " 'degre',\n",
       " 'dehydr',\n",
       " 'del',\n",
       " 'delay',\n",
       " 'delet',\n",
       " 'deliv',\n",
       " 'deliveri',\n",
       " 'dem',\n",
       " 'demand',\n",
       " 'den',\n",
       " 'depend',\n",
       " 'deposit',\n",
       " 'depress',\n",
       " 'derek',\n",
       " 'despar',\n",
       " 'desper',\n",
       " 'destini',\n",
       " 'detail',\n",
       " 'detailsi',\n",
       " 'determin',\n",
       " 'develop',\n",
       " 'dey',\n",
       " 'di',\n",
       " 'dick',\n",
       " 'dict',\n",
       " 'dictionari',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'didnt',\n",
       " 'didntgiv',\n",
       " 'die',\n",
       " 'diesel',\n",
       " 'diet',\n",
       " 'diff',\n",
       " 'differ',\n",
       " 'differb',\n",
       " 'difficult',\n",
       " 'difficulti',\n",
       " 'dificult',\n",
       " 'digit',\n",
       " 'digniti',\n",
       " 'dileepthank',\n",
       " 'dime',\n",
       " 'dimens',\n",
       " 'din',\n",
       " 'dine',\n",
       " 'dinero',\n",
       " 'dinner',\n",
       " 'dinnermsg',\n",
       " 'dint',\n",
       " 'dippeditinadew',\n",
       " 'direct',\n",
       " 'dirt',\n",
       " 'dirti',\n",
       " 'dis',\n",
       " 'disappear',\n",
       " 'disastr',\n",
       " 'disc',\n",
       " 'disclos',\n",
       " 'discount',\n",
       " 'discreet',\n",
       " 'discuss',\n",
       " 'diskyou',\n",
       " 'dislik',\n",
       " 'dismay',\n",
       " 'disturb',\n",
       " 'ditto',\n",
       " 'divorc',\n",
       " 'dizze',\n",
       " 'dled',\n",
       " 'dload',\n",
       " 'dnt',\n",
       " 'do',\n",
       " 'dob',\n",
       " 'dobbi',\n",
       " 'doc',\n",
       " 'doctor',\n",
       " 'doe',\n",
       " 'doesn',\n",
       " 'doesnt',\n",
       " 'dog',\n",
       " 'dogbreath',\n",
       " 'dogg',\n",
       " 'doggi',\n",
       " 'doin',\n",
       " 'doinghow',\n",
       " 'dointerest',\n",
       " 'dollar',\n",
       " 'don',\n",
       " 'done',\n",
       " 'donew',\n",
       " 'dont',\n",
       " 'door',\n",
       " 'dorm',\n",
       " 'dose',\n",
       " 'dot',\n",
       " 'doubl',\n",
       " 'doublefaggot',\n",
       " 'doublemin',\n",
       " 'doubletxt',\n",
       " 'doug',\n",
       " 'dough',\n",
       " 'down',\n",
       " 'download',\n",
       " 'downon',\n",
       " 'downstem',\n",
       " 'dps',\n",
       " 'dracula',\n",
       " 'dramat',\n",
       " 'draw',\n",
       " 'drawpleas',\n",
       " 'dream',\n",
       " 'dreamlov',\n",
       " 'dresser',\n",
       " 'dri',\n",
       " 'drink',\n",
       " 'drinkin',\n",
       " 'drive',\n",
       " 'driver',\n",
       " 'drivin',\n",
       " 'drms',\n",
       " 'drop',\n",
       " 'drpd',\n",
       " 'drug',\n",
       " 'drum',\n",
       " 'drunk',\n",
       " 'drunkard',\n",
       " 'drvgsto',\n",
       " 'dub',\n",
       " 'duck',\n",
       " 'dude',\n",
       " 'due',\n",
       " 'dun',\n",
       " 'dunno',\n",
       " 'duo',\n",
       " 'durban',\n",
       " 'dure',\n",
       " 'dvd',\n",
       " 'each',\n",
       " 'ear',\n",
       " 'earli',\n",
       " 'earlier',\n",
       " 'earlierw',\n",
       " 'earliest',\n",
       " 'earn',\n",
       " 'earth',\n",
       " 'easi',\n",
       " 'easier',\n",
       " 'easter',\n",
       " 'eat',\n",
       " 'eatin',\n",
       " 'ebay',\n",
       " 'eca',\n",
       " 'edha',\n",
       " 'edison',\n",
       " 'edit',\n",
       " 'edrunk',\n",
       " 'educ',\n",
       " 'edukkukaye',\n",
       " 'eeri',\n",
       " 'effect',\n",
       " 'eg',\n",
       " 'eggpotato',\n",
       " 'eh',\n",
       " 'eight',\n",
       " 'eightish',\n",
       " 'either',\n",
       " 'el',\n",
       " 'ela',\n",
       " 'elama',\n",
       " 'els',\n",
       " 'elsewher',\n",
       " 'elvi',\n",
       " 'em',\n",
       " 'email',\n",
       " 'embarrass',\n",
       " 'emerg',\n",
       " 'employ',\n",
       " 'employe',\n",
       " 'en',\n",
       " 'enc',\n",
       " 'end',\n",
       " 'enemi',\n",
       " 'energi',\n",
       " 'engag',\n",
       " 'england',\n",
       " 'english',\n",
       " 'enjoy',\n",
       " 'enjoyin',\n",
       " 'enough',\n",
       " 'enter',\n",
       " 'entertain',\n",
       " 'entir',\n",
       " 'entitl',\n",
       " 'entrepreneur',\n",
       " 'entri',\n",
       " ...]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=tvec.fit(df)\n",
    "X.vocabulary_\n",
    "X.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=tvec.fit_transform(df).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=pd.DataFrame(X, columns=tvec.get_feature_names())\n",
    "\n",
    "#df_new=pd.concat([df_new,Length], axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aah</th>\n",
       "      <th>aaniy</th>\n",
       "      <th>aaooooright</th>\n",
       "      <th>aathilov</th>\n",
       "      <th>aathiwher</th>\n",
       "      <th>aberdeen</th>\n",
       "      <th>abil</th>\n",
       "      <th>abiola</th>\n",
       "      <th>abl</th>\n",
       "      <th>abnorm</th>\n",
       "      <th>...</th>\n",
       "      <th>yrs</th>\n",
       "      <th>yummi</th>\n",
       "      <th>yun</th>\n",
       "      <th>yuo</th>\n",
       "      <th>yup</th>\n",
       "      <th>ywhere</th>\n",
       "      <th>zaher</th>\n",
       "      <th>zed</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zouk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3779 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aah  aaniy  aaooooright  aathilov  aathiwher  aberdeen  abil  abiola  abl  \\\n",
       "0    0      0            0         0          0         0     0       0    0   \n",
       "1    0      0            0         0          0         0     0       0    0   \n",
       "2    0      0            0         0          0         0     0       0    0   \n",
       "3    0      0            0         0          0         0     0       0    0   \n",
       "4    0      0            0         0          0         0     0       0    0   \n",
       "\n",
       "   abnorm  ...  yrs  yummi  yun  yuo  yup  ywhere  zaher  zed  zoe  zouk  \n",
       "0       0  ...    0      0    0    0    0       0      0    0    0     0  \n",
       "1       0  ...    0      0    0    0    0       0      0    0    0     0  \n",
       "2       0  ...    0      0    0    0    0       0      0    0    0     0  \n",
       "3       0  ...    0      0    0    0    0       0      0    0    0     0  \n",
       "4       0  ...    0      0    0    0    0       0      0    0    0     0  \n",
       "\n",
       "[5 rows x 3779 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_new, y, test_size = 0.2, random_state = 225)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model=MultinomialNB().fit(X_train,y_train)\n",
    "\n",
    "y_pred=model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1190,    1],\n",
       "       [   8,  181]], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      1191\n",
      "          1       0.99      0.96      0.98       189\n",
      "\n",
      "avg / total       0.99      0.99      0.99      1380\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[293,   5],\n",
       "       [  5,  42]], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions on test data\n",
    "\n",
    "y_test_pred=model.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98       298\n",
      "          1       0.89      0.89      0.89        47\n",
      "\n",
      "avg / total       0.97      0.97      0.97       345\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    " ## Testing on new reviews \n",
    "\n",
    "example = [\"upto 20% discount on car parking , exclusive offer only for you\"]\n",
    "example_test=tvec.transform(example)\n",
    "#result = model.predict(example)\n",
    "\n",
    "result = model.predict(example_test.toarray())\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "example = [\"I will call you later\"]\n",
    "\n",
    "example_test=tvec.transform(example)\n",
    "#result = model.predict(example)\n",
    "\n",
    "result = model.predict(example_test.toarray())\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
